(window.webpackJsonp=window.webpackJsonp||[]).push([[6],{352:function(e,t,a){"use strict";a.r(t);var r=a(42),o=Object(r.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"getting-started"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#getting-started"}},[e._v("#")]),e._v(" Getting Started")]),e._v(" "),a("h3",{attrs:{id:"prerequisites"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#prerequisites"}},[e._v("#")]),e._v(" Prerequisites")]),e._v(" "),a("p",[e._v("In order to follow along this workshop in the best possible way, some requirements should be met.")]),e._v(" "),a("p",[e._v("First of all, you need to have some basic knowledge of Apache Kafka: what are topics, partitions, brokers as this workshop will not explain these concepts.")]),e._v(" "),a("p",[e._v("Secondly, you need to have the following tools installed on your computer:")]),e._v(" "),a("ul",[a("li",[a("a",{attrs:{href:"https://git-scm.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Git"),a("OutboundLink")],1),e._v(",")]),e._v(" "),a("li",[a("a",{attrs:{href:"https://www.docker.com/get-started",target:"_blank",rel:"noopener noreferrer"}},[e._v("Docker"),a("OutboundLink")],1),e._v(",")]),e._v(" "),a("li",[a("a",{attrs:{href:"https://docs.docker.com/compose/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Docker Compose"),a("OutboundLink")],1),e._v(",")]),e._v(" "),a("li",[e._v("and your favorite IDE")])]),e._v(" "),a("h2",{attrs:{id:"introduction"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[e._v("#")]),e._v(" Introduction")]),e._v(" "),a("p",[e._v("Kafka is increasingly used, and as a message broker it is often placed at the center of several software architectures, which can bring it to a critical place. Keeping track of what's hapenning around and inside the cluster is always a good idea and this is precisely what we will be doing during this workshop.")]),e._v(" "),a("p",[e._v("As you may already know Kafka comes in two main distributions, the first is provided by the "),a("a",{attrs:{href:"https://apache.org",target:"_blank",rel:"noopener noreferrer"}},[e._v("Apache foundation"),a("OutboundLink")],1),e._v(" and was first released on april 2014. And the second is provided by "),a("a",{attrs:{href:"https://www.confluent.io",target:"_blank",rel:"noopener noreferrer"}},[e._v("Confluent"),a("OutboundLink")],1),e._v(" and based upon the first one.")]),e._v(" "),a("p",[e._v("Confluents offers a community edition and an enterprise edition which adds the following:")]),e._v(" "),a("ul",[a("li",[e._v("Extra connectors (some are also included in the community edition)")]),e._v(" "),a("li",[e._v("Graphical User Interface (Control Center)")]),e._v(" "),a("li",[e._v("Security features (RBAC, Audit logs...)")]),e._v(" "),a("li",[e._v("Replication tool")])]),e._v(" "),a("p",[e._v("(you can check out the full "),a("a",{attrs:{href:"https://www.confluent.io/product/confluent-platform",target:"_blank",rel:"noopener noreferrer"}},[e._v("feature list"),a("OutboundLink")],1),e._v(".)")]),e._v(" "),a("p",[e._v("We will be using Confluent Kafka to compare what can be done with the built-in tools with what can be done with dedicated tools.")]),e._v(" "),a("p",[e._v("In order to do that we will:")]),e._v(" "),a("ul",[a("li",[e._v("create a cluster, and perform checks to make sure everything will run as smoothly as possible")]),e._v(" "),a("li",[e._v("add some data")]),e._v(" "),a("li",[e._v("discover what can be done with Confluent tools")]),e._v(" "),a("li",[e._v("check JMX metrics with JConsole")]),e._v(" "),a("li",[e._v("export a few of these metrics with prometheus")]),e._v(" "),a("li",[e._v("use Grafana to get a comprehensive view of the cluster")])]),e._v(" "),a("h2",{attrs:{id:"setup"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#setup"}},[e._v("#")]),e._v(" Setup")]),e._v(" "),a("p",[e._v("Clone the repo")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("git clone git@github.com:vgallet/kafka-monitoring.git\n")])])]),a("p",[e._v("Start the cluster")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("docker-compose -f kafka-cluster.yml up -d\n")])])]),a("p",[e._v("Check container status")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("docker-compose -f kafka-cluster.yml ps\n")])])]),a("p",[e._v("The result should be")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("           Name                       Command            State                       Ports                     \n---------------------------------------------------------------------------------------------------------------\nkafka-monitoring_kafka-1_1   /etc/confluent/docker/run   Up      0.0.0.0:1098->1098/tcp, 0.0.0.0:9092->9092/tcp\nkafka-monitoring_kafka-2_1   /etc/confluent/docker/run   Up      9092/tcp                                      \nkafka-monitoring_kafka-3_1   /etc/confluent/docker/run   Up      9092/tcp                                      \nkafka-monitoring_zk-1_1      /etc/confluent/docker/run   Up      2181/tcp, 2888/tcp, 3888/tcp                  \nkafka-monitoring_zk-2_1      /etc/confluent/docker/run   Up      2181/tcp, 2888/tcp, 3888/tcp                  \nkafka-monitoring_zk-3_1      /etc/confluent/docker/run   Up      2181/tcp, 2888/tcp, 3888/tcp \n")])])]),a("p",[e._v("A container may not start correctly. If it happens, you can simply stop and delete all containers and linked volumes.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("               Name                           Command            State               Ports            \n------------------------------------------------------------------------------------------------------\nkafka-monitoring_kafka-1_1           /etc/confluent/docker/run   Exit 1                               \nkafka-monitoring_kafka-2_1           /etc/confluent/docker/run   Exit 1                               \nkafka-monitoring_kafka-3_1           /etc/confluent/docker/run   Exit 1  \n")])])]),a("p",[e._v("Stop and clean all volumes")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("docker-compose -f kafka-cluster.yml down -v\n")])])]),a("h2",{attrs:{id:"the-cluster"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#the-cluster"}},[e._v("#")]),e._v(" The Cluster")]),e._v(" "),a("p",[e._v("As you can see from the file "),a("code",[e._v("kafka-cluster.yml")]),e._v(", the cluster is composed with three Apache Kafka brokers and three Apache ZooKeeper nodes.")]),e._v(" "),a("div",{staticStyle:{"text-align":"center"}},[a("img",{attrs:{src:"Schema_Kafka_Cluster.png"}})]),e._v(" "),a("p",[e._v("This is a vanilla installation! During this workshop, we are going to see how to monitor the brokers using basic command line, off-the-shelf tools and JMX metrics.")]),e._v(" "),a("div",{staticStyle:{"text-align":"center"}},[a("img",{attrs:{src:"Schema_All.png"}})])])}),[],!1,null,null,null);t.default=o.exports}}]);